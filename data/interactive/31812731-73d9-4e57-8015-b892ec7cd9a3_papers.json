{
  "metadata": {
    "topic": "EEG noise removal transformer",
    "session_id": "31812731-73d9-4e57-8015-b892ec7cd9a3",
    "searched_at": "2026-01-06T14:52:47.891231",
    "queries": [
      "EEG noise removal transformer"
    ],
    "total_papers": 38
  },
  "papers": [
    {
      "id": "openalex_fc7380f6d09f",
      "title": "ART: Artifact Removal Transformer for Reconstructing Noise-Free Multichannel Electroencephalographic Signals",
      "authors": [
        "Chun‐Hsiang Chuang",
        "Kong-Yi Chang",
        "Chih-Sheng Huang",
        "Anne-Mei Bessas"
      ],
      "year": 2024,
      "abstract": "Artifact removal in electroencephalography (EEG) is a longstanding challenge that significantly impacts neuroscientific analysis and brain-computer interface (BCI) performance. Tackling this problem demands advanced algorithms, extensive noisy-clean training data, and thorough evaluation strategies. This study presents the Artifact Removal Transformer (ART), an innovative EEG denoising model employing transformer architecture to adeptly capture the transient millisecond-scale dynamics characteristic of EEG signals. Our approach offers a holistic, end-to-end denoising solution for diverse artifact types in multichannel EEG data. We enhanced the generation of noisy-clean EEG data pairs using an independent component analysis, thus fortifying the training scenarios critical for effective supervised learning. We performed comprehensive validations using a wide range of open datasets from various BCI applications, employing metrics like mean squared error and signal-to-noise ratio, as well as sophisticated techniques such as source localization and EEG component classification. Our evaluations confirm that ART surpasses other deep-learning-based artifact removal methods, setting a new benchmark in EEG signal processing. This advancement not only boosts the accuracy and reliability of artifact removal but also promises to catalyze further innovations in the field, facilitating the study of brain dynamics in naturalistic environments.",
      "doi": "10.48550/arxiv.2409.07326",
      "source": "openalex",
      "citations": 3,
      "journal": "arXiv (Cornell University)"
    },
    {
      "id": "openalex_d808cd5e830b",
      "title": "Feature dimensionality reduction: a review",
      "authors": [
        "Weikuan Jia",
        "Meili Sun",
        "Jian Lian",
        "Sujuan Hou"
      ],
      "year": 2022,
      "abstract": "Abstract As basic research, it has also received increasing attention from people that the “curse of dimensionality” will lead to increase the cost of data storage and computing; it also influences the efficiency and accuracy of dealing with problems. Feature dimensionality reduction as a key link in the process of pattern recognition has become one hot and difficulty spot in the field of pattern recognition, machine learning and data mining. It is one of the most challenging research fields, which has been favored by most of the scholars’ attention. How to implement “low loss” in the process of feature dimension reduction, keep the nature of the original data, find out the best mapping and get the optimal low dimensional data are the keys aims of the research. In this paper, two-dimensionality reduction methods, feature selection and feature extraction, are introduced; the current mainstream dimensionality reduction algorithms are analyzed, including the method for small sample and method based on deep learning. For each algorithm, examples of their application are given and the advantages and disadvantages of these methods are evaluated.",
      "doi": "10.1007/s40747-021-00637-x",
      "source": "openalex",
      "citations": 625,
      "journal": "Complex & Intelligent Systems"
    },
    {
      "id": "openalex_c3faef44f812",
      "title": "CT-DCENet: Deep EEG Denoising via CNN-Transformer-Based Dual-Stage Collaborative Ensemble Learning",
      "authors": [
        "Yunbo Tang",
        "Weirong Huang",
        "Chuanxi Chen",
        "Dan Chen"
      ],
      "year": 2025,
      "abstract": "Electroencephalogram (EEG) artifact removal has been investigated for decades with the goal of reconstructing the clean signals for the subsequent EEG analysis. However, existing denoising methods still have limited capabilities to handle the highly mixed artifacts and the fine-grained temporal dependency of artifact-free EEG without a priori knowledge of the artifacts. To address the challenges, this study proposes a CNN-Transformer-based dual-stage collaborative ensemble learning framework (namely CT-DCENet) in the form of three modules: 1) randomized collaboration module initially utilizes four individual learners to reveal multi-group morphological characteristics of the denoised EEG, 2) linear ensemble module integrates the outputs of four individual learners via weighted linear combination to preliminarily estimate the denoised EEG, 3) information complementation module takes in the residual between the contaminated EEG and the above estimated EEG, and critically applies CNN-Transformer-based feature extractor and denoising head to learn the detailed characteristics of the denoised EEG. CT-DCENet is conducted in a dual-stage training manner to derive the morphological characteristics & the detailed characteristics of the artifact-free EEG successively. The experimental results on the public EEG datasets indicate that 1) CT-DCENet significantly outperforms the state-of-the-art counterparts (e.g., DuoCL, GCTNet) under the conditions of various artifacts and noise intensities, where the increases of SNR & PCC are 0.79 dB, 0.6% and the decrease of RRMSE is 1.9% for the removal of EMG, ECG, EOG mixed artifacts, 2) the reconstructed EEG by CT-DCENet can well fit the clean EEG with a low error achieved, especially for the peak amplitude, the high-frequency area and the boundary area of the EEG waveform, providing promising EEG data for the downstream task-oriented EEG analysis.",
      "doi": "10.1109/jbhi.2025.3535592",
      "source": "openalex",
      "citations": 3,
      "journal": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "id": "openalex_0a1877886b4f",
      "title": "Augmenting brain-computer interfaces with ART: An artifact removal transformer for reconstructing multichannel EEG signals",
      "authors": [
        "Chun‐Hsiang Chuang",
        "Kong-Yi Chang",
        "Chih-Sheng Huang",
        "Anne-Mei Bessas"
      ],
      "year": 2025,
      "abstract": "Artifact removal in electroencephalography (EEG) is a longstanding challenge that significantly impacts neuroscientific analysis and brain-computer interface (BCI) performance. Tackling this problem demands advanced algorithms, extensive noisy-clean training data, and thorough evaluation strategies. This study presents the Artifact Removal Transformer (ART), an innovative EEG denoising model employing transformer architecture to adeptly capture the transient millisecond-scale dynamics characteristic of EEG signals. Our approach offers a holistic, end-to-end denoising solution that simultaneously addresses multiple artifact types in multichannel EEG data. We enhanced the generation of noisy-clean EEG data pairs using an independent component analysis, thus fortifying the training scenarios critical for effective supervised learning. We performed comprehensive validations using a wide range of open datasets from various BCI applications, employing metrics like mean squared error and signal-to-noise ratio, as well as sophisticated techniques such as source localization and EEG component classification. Our evaluations confirm that ART surpasses other deep-learning-based artifact removal methods, setting a new benchmark in EEG signal processing. This advancement not only boosts the accuracy and reliability of artifact removal but also promises to catalyze further innovations in the field, facilitating the study of brain dynamics in naturalistic environments.",
      "doi": "10.1016/j.neuroimage.2025.121123",
      "source": "openalex",
      "citations": 2,
      "journal": "NeuroImage"
    },
    {
      "id": "openalex_61e366699dd1",
      "title": "A Review of Wavelet Analysis and Its Applications: Challenges and Opportunities",
      "authors": [
        "Tiantian Guo",
        "Tongpo Zhang",
        "Eng Gee Lim",
        "Miguel López‐Benítez",
        "Fei Ma",
        "Limin Yu"
      ],
      "year": 2022,
      "abstract": "As a general and rigid mathematical tool, wavelet theory has found many applications and is constantly developing. This article reviews the development history of wavelet theory, from the construction method to the discussion of wavelet properties. Then it focuses on the design and expansion of wavelet transform. The main models and algorithms of wavelet transform are discussed. The construction of rational wavelet transform (RWT) is provided by examples emphasizing the advantages of RWT over traditional wavelet transform through a review of the literature. The combination of wavelet theory and neural networks is one of the key points of the review. The review covers the evolution of Wavelet Neural Network (WNN), the system architecture and algorithm implementation. The review of the literature indicates the advantages and a clear trend of fast development in WNN that can be combined with existing neural network algorithms. This article also introduces the categories of wavelet-based applications. The advantages of wavelet analysis are summarized in terms of application scenarios with a comparison of results. Through the review, new research challenges and gaps have been clarified, which will serve as a guide for potential wavelet-based applications and new system designs.",
      "doi": "10.1109/access.2022.3179517",
      "source": "openalex",
      "citations": 393,
      "journal": "IEEE Access"
    },
    {
      "id": "openalex_767783131220",
      "title": "Early Disease Detection Using AI: A Deep Learning Approach to Predicting Cancer and Neurological Disorders",
      "authors": [
        "Sahil Kumar"
      ],
      "year": 2025,
      "abstract": "Early diagnosis of life-threatening illnesses, like cancers and neurological disorders, is crucial for enhancing patient survival rates, minimizing treatment expenses, and the administration of early medical intervention. Yet, conventional diagnostic techniques are usually beset by issues that include high reliance on expert opinion, time consumption, and fluctuating accuracy—particularly during the initial phases of disease progression. The availability of huge medical datasets, coupled with the recent explosion in Artificial Intelligence (AI), specifically in the area of deep learning, has opened up a new avenue for strengthening early diagnostic powers. This study compares and contrasts the performance of five deep learning architectures—Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), Transformers, and a hybrid CNN-RNN model—against the early detection of cancer and neurological diseases. Public datasets comprising histopathological images, EEG signals, and MRI scans were utilized for training and testing the models. Essential preprocessing methods, including normalization, augmentation, and noise removal, were employed to enhance model performance with regard to both spatial and sequential data types. The performance of models was evaluated using performance measures such as accuracy, precision, recall, F1-score, and ROC-AUC. The results of experiments demonstrate that the Transformer and Hybrid CNN-RNN models surpassed the performance of other models on both disease classifications with detection accuracies of over 92%. The results point to the efficacy of multi-context learning methods, which have the capability of learning both spatial and temporal features in complicated biomedical data simultaneously. The research illustrates that deep learning can play a substantial role in enhancing early disease diagnosis by providing scalable, effective, and precise diagnostic solutions. Furthermore, it lays the foundation for the future incorporation of explainable artificial intelligence, multi-modal data fusion, and implementation of AI models in real-time clinical environments. Through connecting machine learning advances with practical healthcare applications, the research is building intelligent systems to assist clinicians in making life-critical and timely decisions",
      "doi": "10.18535/ijsrm/v13i04.mp02",
      "source": "openalex",
      "citations": 6,
      "journal": "International Journal of Scientific Research and Management (IJSRM)"
    },
    {
      "id": "openalex_3059b866d3fd",
      "title": "Shared computational principles for language processing in humans and deep language models",
      "authors": [
        "Ariel Goldstein",
        "Zaid Zada",
        "Eliav Buchnik",
        "Mariano Schain",
        "Amy Price",
        "Bobbi Aubrey",
        "Samuel A. Nastase",
        "Amir Feder",
        "Dotan Emanuel",
        "Alon Cohen"
      ],
      "year": 2022,
      "abstract": "Abstract Departing from traditional linguistic models, advances in deep learning have resulted in a new type of predictive (autoregressive) deep language models (DLMs). Using a self-supervised next-word prediction task, these models generate appropriate linguistic responses in a given context. In the current study, nine participants listened to a 30-min podcast while their brain responses were recorded using electrocorticography (ECoG). We provide empirical evidence that the human brain and autoregressive DLMs share three fundamental computational principles as they process the same natural narrative: (1) both are engaged in continuous next-word prediction before word onset; (2) both match their pre-onset predictions to the incoming word to calculate post-onset surprise; (3) both rely on contextual embeddings to represent words in natural contexts. Together, our findings suggest that autoregressive DLMs provide a new and biologically feasible computational framework for studying the neural basis of language.",
      "doi": "10.1038/s41593-022-01026-4",
      "source": "openalex",
      "citations": 387,
      "journal": "Nature Neuroscience"
    },
    {
      "id": "openalex_0f4a836c998c",
      "title": "A Review of Issues Related to Data Acquisition and Analysis in EEG/MEG Studies",
      "authors": [
        "Aina Puce",
        "Matti Hämäläinen"
      ],
      "year": 2017,
      "abstract": "Electroencephalography (EEG) and magnetoencephalography (MEG) are non-invasive electrophysiological methods, which record electric potentials and magnetic fields due to electric currents in synchronously-active neurons. With MEG being more sensitive to neural activity from tangential currents and EEG being able to detect both radial and tangential sources, the two methods are complementary. Over the years, neurophysiological studies have changed considerably: high-density recordings are becoming de rigueur; there is interest in both spontaneous and evoked activity; and sophisticated artifact detection and removal methods are available. Improved head models for source estimation have also increased the precision of the current estimates, particularly for EEG and combined EEG/MEG. Because of their complementarity, more investigators are beginning to perform simultaneous EEG/MEG studies to gain more complete information about neural activity. Given the increase in methodological complexity in EEG/MEG, it is important to gather data that are of high quality and that are as artifact free as possible. Here, we discuss some issues in data acquisition and analysis of EEG and MEG data. Practical considerations for different types of EEG and MEG studies are also discussed.",
      "doi": "10.3390/brainsci7060058",
      "source": "openalex",
      "citations": 180,
      "journal": "Brain Sciences"
    },
    {
      "id": "openalex_6c1456acdfa6",
      "title": "Motor Imagery EEG Signals Classification Based on Mode Amplitude and Frequency Components Using Empirical Wavelet Transform",
      "authors": [
        "Muhammad Tariq Sadiq",
        "Xiaojun Yu",
        "Zhaohui Yuan",
        "Zeming Fan",
        "Ateeq Ur Rehman",
        "Guoqi Li",
        "Gaoxi Xiao"
      ],
      "year": 2019,
      "abstract": "As one of the key techniques determining the overall system performances, efficient and reliable algorithms for improving the classification accuracy of motor imagery (MI) based electroencephalography (EEG) signals are highly desired for the development of brain-computer interface (BCI) systems. In this study, we propose, for the first time to the best of our knowledge, a novel data adaptive empirical wavelet transform (EWT) based signal decomposition method for improving the classification accuracy of MI based EEG signals. Specifically, to reduce the system complexity and execution time, the proposed method selects 18 electrodes out of 118 to analyze the non-stationary and nonlinear EEG signal behaviors. Meanwhile, the method adopts the Welch power spectral density (PSD) analysis method for single mode selection out of the total 10 for each channel, and the Hilbert transform (HT) method for both instantaneous amplitude (IA) and instantaneous frequency (IF) signal components extraction for each selected mode. With seven commonly used machine-learning classifiers adopted, extensive experiments were conducted with the benchmark dataset IVa from BCI competition III to evaluate the performance of the proposed method. Results show that with the IA and IF component features being tested using the least-square support vector machine (LS-SVM) classifier, the EWT method achieves an average classification accuracy of 95.2% and 94.6% respectively, which is higher as compared with the existing methods. While for every participant, a classification accuracy of at least 80% could be achieved by employing a single feature only. Results also show that a combination of EWT and higher order statistics features, which contain both kurtosis and skewness of the extracted instantaneous components, help achieve a higher success rate. The better performances of EWT over those of the existing methods demonstrate the effectiveness and great potential of EWT for BCI system applications.",
      "doi": "10.1109/access.2019.2939623",
      "source": "openalex",
      "citations": 151,
      "journal": "IEEE Access"
    },
    {
      "id": "openalex_0dc53e90a8d8",
      "title": "Deep Learning in EEG-Based BCIs: A Comprehensive Review of Transformer Models, Advantages, Challenges, and Applications",
      "authors": [
        "Berdakh Abibullaev",
        "Aigerim Keutayeva",
        "Amin Zollanvari"
      ],
      "year": 2023,
      "abstract": "Brain-computer interfaces (BCIs) have undergone significant advancements in recent years. The integration of deep learning techniques, specifically transformers, has shown promising development in research and application domains. Transformers, which were originally designed for natural language processing, have now made notable inroads into BCIs, offering a unique self-attention mechanism that adeptly handles the temporal dynamics of brain signals. This comprehensive survey delves into the application of transformers in BCIs, providing readers with a lucid understanding of their foundational principles, inherent advantages, potential challenges, and diverse applications. In addition to discussing the benefits of transformers, we also address their limitations, such as computational overhead, interpretability concerns, and the data-intensive nature of these models, providing a well-rounded analysis. Furthermore, the paper sheds light on the myriad of BCI applications that have benefited from the incorporation of transformers. These applications span from motor imagery decoding, emotion recognition, and sleep stage analysis to novel ventures such as speech reconstruction. This review serves as a holistic guide for researchers and practitioners, offering a panoramic view of the transformative potential of transformers in the BCI landscape. With the inclusion of examples and references, readers will gain a deeper understanding of the topic and its significance in the field.",
      "doi": "10.1109/access.2023.3329678",
      "source": "openalex",
      "citations": 75,
      "journal": "IEEE Access"
    },
    {
      "id": "openalex_ad40f7648f23",
      "title": "Window Functions and Their Applications in Signal Processing",
      "authors": [
        "K.M.M. Prabhu"
      ],
      "year": 2018,
      "abstract": "Window functions—otherwise known as weighting functions, tapering functions, or apodization functions—are mathematical functions that are zero-valued outside the chosen interval. They are well established as a vital part of digital signal processing. Window Functions and their Applications in Signal Processing presents an exhaustive and detailed account of window functions and their applications in signal processing, focusing on the areas of digital spectral analysis, design of FIR filters, pulse compression radar, and speech signal processing. Comprehensively reviewing previous research and recent developments, this book: Provides suggestions on how to choose a window function for particular applications Discusses Fourier analysis techniques and pitfalls in the computation of the DFT Introduces window functions in the continuous-time and discrete-time domains Considers two implementation strategies of window functions in the time- and frequency domain Explores well-known applications of window functions in the fields of radar, sonar, biomedical signal analysis, audio processing, and synthetic aperture radar",
      "doi": "10.1201/9781315216386",
      "source": "openalex",
      "citations": 126,
      "journal": null
    },
    {
      "id": "openalex_2e397d70a940",
      "title": "Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram",
      "authors": [
        "Mikito Ogino",
        "Yasue Mitsukura"
      ],
      "year": 2018,
      "abstract": "Drowsiness detection has been studied in the context of evaluating products, assessing driver alertness, and managing office environments. Drowsiness level can be readily detected through measurement of human brain activity. The electroencephalogram (EEG), a device whose application relies on adhering electrodes to the scalp, is the primary method used to monitor brain activity. The many electrodes and wires required to perform an EEG place considerable constraints on the movement of users, and the cost of the device limits its availability. For these reasons, conventional EEG devices are not used in practical studies and businesses. Many potential practical applications could benefit from the development of a wire-free, low-priced device; however, it remains to be elucidated whether portable EEG devices can be used to estimate human drowsiness levels and applied within practical research settings and businesses. In this study, we outline the development of a drowsiness detection system that makes use of a low-priced, prefrontal single-channel EEG device and evaluate its performance in an offline analysis and a practical experiment. Firstly, for the development of the system, we compared three feature extraction methods: power spectral density (PSD), autoregressive (AR) modeling, and multiscale entropy (MSE) for detecting characteristics of an EEG. In order to efficiently select a meaningful PSD, we utilized step-wise linear discriminant analysis (SWLDA). Time-averaging and robust-scaling were used to fit the data for pattern recognition. Pattern recognition was performed by a support vector machine (SVM) with a radial basis function (RBF) kernel. The optimal hyperparameters for the SVM were selected by the grind search method so as to increase drowsiness detection accuracy. To evaluate the performance of the detections, we calculated classification accuracy using the SVM through 10-fold cross-validation. Our model achieved a classification accuracy of 72.7% using the PSD with SWLDA and the SVM. Secondly, we conducted a practical study using the system and evaluated its performance in a practical situation. There was a significant difference (* p &lt; 0.05) between the drowsiness-evoked task and concentration-needed task. Our results demonstrate the efficacy of our low-priced portable drowsiness detection system in quantifying drowsy states. We anticipate that our system will be useful to practical studies with aims as diverse as measurement of classroom mental engagement, evaluation of movies, and office environment evaluation.",
      "doi": "10.3390/s18124477",
      "source": "openalex",
      "citations": 93,
      "journal": "Sensors"
    },
    {
      "id": "openalex_c0e7df96423b",
      "title": "A comprehensive literature review of the applications of AI techniques through the lifecycle of industrial equipment",
      "authors": [
        "Mahboob Elahi",
        "Samuel Olaiya Afolaranmi",
        "José L. Martínez Lastra",
        "José Antonio Pérez García"
      ],
      "year": 2023,
      "abstract": null,
      "doi": "10.1007/s44163-023-00089-x",
      "source": "openalex",
      "citations": 211,
      "journal": "Discover Artificial Intelligence"
    },
    {
      "id": "openalex_fb28a4513cb5",
      "title": "Exploring Convolutional Neural Network Architectures for EEG Feature Extraction",
      "authors": [
        "Ildar Rakhmatulin",
        "Minh-Son Dao",
        "Amir Nassibi",
        "Danilo P. Mandic"
      ],
      "year": 2024,
      "abstract": "The main purpose of this paper is to provide information on how to create a convolutional neural network (CNN) for extracting features from EEG signals. Our task was to understand the primary aspects of creating and fine-tuning CNNs for various application scenarios. We considered the characteristics of EEG signals, coupled with an exploration of various signal processing and data preparation techniques. These techniques include noise reduction, filtering, encoding, decoding, and dimension reduction, among others. In addition, we conduct an in-depth analysis of well-known CNN architectures, categorizing them into four distinct groups: standard implementation, recurrent convolutional, decoder architecture, and combined architecture. This paper further offers a comprehensive evaluation of these architectures, covering accuracy metrics, hyperparameters, and an appendix that contains a table outlining the parameters of commonly used CNN architectures for feature extraction from EEG signals.",
      "doi": "10.3390/s24030877",
      "source": "openalex",
      "citations": 73,
      "journal": "Sensors"
    },
    {
      "id": "openalex_3831459d2051",
      "title": "SQUIDs in biomagnetism: a roadmap towards improved healthcare",
      "authors": [
        "Rainer Körber",
        "Jan-Hendrik Storm",
        "H.C. Seton",
        "Jyrki P. Mäkelä",
        "Ritva Paetau",
        "Lauri Parkkonen",
        "Christoph Pfeiffer",
        "Bushra Riaz",
        "Justin F. Schneiderman",
        "Hui Dong"
      ],
      "year": 2016,
      "abstract": "Globally, the demand for improved health care delivery while managing escalating costs is a major challenge. Measuring the biomagnetic fields that emanate from the human brain already impacts the treatment of epilepsy, brain tumours and other brain disorders. This roadmap explores how superconducting technologies are poised to impact health care. Biomagnetism is the study of magnetic fields of biological origin. Biomagnetic fields are typically very weak, often in the femtotesla range, making their measurement challenging. The earliest in vivo human measurements were made with room-temperature coils. In 1963, Baule and McFee (1963 Am. Heart J. 55 95-6) reported the magnetic field produced by electric currents in the heart ('magnetocardiography'), and in 1968, Cohen (1968 Science 161 784-6) described the magnetic field generated by alpha-rhythm currents in the brain ('magnetoencephalography'). Subsequently, in 1970, Cohen et al (1970 Appl. Phys. Lett. 16 278-80) reported the recording of a magnetocardiogram using a Superconducting QUantum Interference Device (SQUID). Just two years later, in 1972, Cohen (1972 Science 175 664-6) described the use of a SQUID in magnetoencephalography. These last two papers set the scene for applications of SQUIDs in biomagnetism, the subject of this roadmap. The SQUID is a combination of two fundamental properties of superconductors. The first is flux quantization - the fact that the magnetic flux ? in a closed superconducting loop is quantized in units of the magnetic flux quantum, ?0 ? h/2e, ? 2.07 × 10-15 Tm2 (Deaver and Fairbank 1961 Phys. Rev. Lett. 7 43-6, Doll R and Nabauer M 1961 Phys. Rev. Lett. 7 51-2). Here, h is the Planck constant and e the elementary charge. The second property is the Josephson effect, predicted in 1962 by Josephson (1962 Phys. Lett. 1 251-3) and observed by Anderson and Rowell (1963 Phys. Rev. Lett. 10 230-2) in 1963. The Josephson junction consists of two weakly coupled superconductors separated by a tunnel barrier or other weak link. A tiny electric current is able to flow between the superconductors as a supercurrent, without developing a voltage across them. At currents above the 'critical current' (maximum supercurrent), however, a voltage is developed. In 1964, Jaklevic et al (1964 Phys. Rev. Lett. 12 159-60) observed quantum interference between two Josephson junctions connected in series on a superconducting loop, giving birth to the dc SQUID. The essential property of the SQUID is that a steady increase in the magnetic flux threading the loop causes the critical current to oscillate with a period of one flux quantum. In today's SQUIDs, using conventional semiconductor readout electronics, one can typically detect a change in ? corresponding to 10-6 ?0 in one second. Although early practical SQUIDs were usually made from bulk superconductors, for example, niobium or Pb-Sn solder blobs, today's devices are invariably made from thin superconducting films patterned with photolithography or even electron lithography. An extensive description of SQUIDs and their applications can be found in the SQUID Handbooks (Clarke and Braginski 2004 Fundamentals and Technology of SQUIDs and SQUID Systems vol I (Weinheim, Germany: Wiley-VCH), Clarke and Braginski 2006 Applications of SQUIDs and SQUID Systems vol II (Weinheim, Germany: Wiley-VCH)). The roadmap begins (chapter 1) with a brief review of the state-of-the-art of SQUID-based magnetometers and gradiometers for biomagnetic measurements. The magnetic field noise referred to the pick-up loop is typically a few fT Hz-1/2, often limited by noise in the metallized thermal insulation of the dewar rather than by intrinsic SQUID noise. The authors describe a pathway to achieve an intrinsic magnetic field noise as low as 0.1 fT Hz-1/2, approximately the Nyquist noise of the human body. They also descibe a technology to defeat dewar noise. Chapter 2 reviews the neuroscientific and clinical use of magnetoencephalography (MEG), by far the most widespread application of biomagnetism with systems containing typically 300 sensors cooled to liquid-helium temperature, 4.2 K. Two important clinical applications are presurgical mapping of focal epilepsy and of eloquent cortex in brain-tumor patients. Reducing the sensor-to-brain separation and the system noise level would both improve spatial resolution. The very recent commercial innovation that replaces the need for frequent manual transfer of liquid helium with an automated system that collects and liquefies the gas and transfers the liquid to the dewar will make MEG systems more accessible. [...]",
      "doi": "10.1088/0953-2048/29/11/113001",
      "source": "openalex",
      "citations": 90,
      "journal": "Superconductor Science and Technology"
    },
    {
      "id": "openalex_44dd27f219e6",
      "title": "Shaping high-performance wearable robots for human motor and sensory reconstruction and enhancement",
      "authors": [
        "Haisheng Xia",
        "Yuchong Zhang",
        "Nona Rajabi",
        "Farzaneh Taleb",
        "Qunting Yang",
        "Danica Kragić",
        "Zhijun Li"
      ],
      "year": 2024,
      "abstract": null,
      "doi": "10.1038/s41467-024-46249-0",
      "source": "openalex",
      "citations": 79,
      "journal": "Nature Communications"
    },
    {
      "id": "openalex_4d98e53ed69d",
      "title": "Emotion Recognition Using Different Sensors, Emotion Models, Methods and Datasets: A Comprehensive Review",
      "authors": [
        "Yujian Cai",
        "Xingguang Li",
        "Jinsong Li"
      ],
      "year": 2023,
      "abstract": "In recent years, the rapid development of sensors and information technology has made it possible for machines to recognize and analyze human emotions. Emotion recognition is an important research direction in various fields. Human emotions have many manifestations. Therefore, emotion recognition can be realized by analyzing facial expressions, speech, behavior, or physiological signals. These signals are collected by different sensors. Correct recognition of human emotions can promote the development of affective computing. Most existing emotion recognition surveys only focus on a single sensor. Therefore, it is more important to compare different sensors or unimodality and multimodality. In this survey, we collect and review more than 200 papers on emotion recognition by literature research methods. We categorize these papers according to different innovations. These articles mainly focus on the methods and datasets used for emotion recognition with different sensors. This survey also provides application examples and developments in emotion recognition. Furthermore, this survey compares the advantages and disadvantages of different sensors for emotion recognition. The proposed survey can help researchers gain a better understanding of existing emotion recognition systems, thus facilitating the selection of suitable sensors, algorithms, and datasets.",
      "doi": "10.3390/s23052455",
      "source": "openalex",
      "citations": 94,
      "journal": "Sensors"
    },
    {
      "id": "openalex_451e97a99ce5",
      "title": "Role of machine learning and deep learning techniques in EEG-based BCI emotion recognition system: a review",
      "authors": [
        "Priyadarsini Samal",
        "Mohammad Farukh Hashmi"
      ],
      "year": 2024,
      "abstract": "Abstract Emotion is a subjective psychophysiological reaction coming from external stimuli which impacts every aspect of our daily lives. Due to the continuing development of non-invasive and portable sensor technologies, such as brain-computer interfaces (BCI), intellectuals from several fields have been interested in emotion recognition techniques. Human emotions can be recognised using a variety of behavioural cues, including gestures and body language, voice, and physiological markers. The first three, however, might be ineffective because people sometimes conceal their genuine emotions either intentionally or unknowingly. More precise and objective emotion recognition can be accomplished using physiological signals. Among other physiological signals, Electroencephalogram (EEG) is more responsive and sensitive to variation in affective states. Various EEG-based emotion recognition methods have recently been introduced. This study reviews EEG-based BCIs for emotion identification and gives an outline of the progress made in this field. A summary of the datasets and techniques utilised to evoke human emotions and various emotion models is also given. We discuss several EEG feature extractions, feature selection/reduction, machine learning, and deep learning algorithms in accordance with standard emotional identification process. We provide an overview of the human brain's EEG rhythms, which are closely related to emotional states. We also go over a number of EEG-based emotion identification research and compare numerous machine learning and deep learning techniques. In conclusion, this study highlights the applications, challenges and potential areas for future research in identification and classification of human emotional states.",
      "doi": "10.1007/s10462-023-10690-2",
      "source": "openalex",
      "citations": 79,
      "journal": "Artificial Intelligence Review"
    },
    {
      "id": "openalex_3dc7561affc4",
      "title": "Remote monitoring of cardiorespiratory signals from a hovering unmanned aerial vehicle",
      "authors": [
        "Ali Al‐Naji",
        "Asanka G. Perera",
        "Javaan Chahl"
      ],
      "year": 2017,
      "abstract": "The experimental results demonstrated that the proposed system with and without the magnification process achieves robust and accurate readings and have significant correlations compared to a standard pulse oximeter and Piezo respiratory belt. Also, the squared correlation coefficient, root mean square error, and mean error rate yielded by the proposed method with and without the magnification process were significantly better than the state-of-the-art methodologies, including independent component analysis (ICA) and principal component analysis (PCA).",
      "doi": "10.1186/s12938-017-0395-y",
      "source": "openalex",
      "citations": 72,
      "journal": "BioMedical Engineering OnLine"
    },
    {
      "id": "openalex_570400077d3c",
      "title": "Epileptic Seizures Detection in EEG Signals Using Fusion Handcrafted and Deep Learning Features",
      "authors": [
        "Anis Malekzadeh",
        "Assef Zare",
        "Mahdi Yaghoobi",
        "Hamid-Reza Kobravi",
        "Roohallah Alizadehsani"
      ],
      "year": 2021,
      "abstract": "Epilepsy is a brain disorder disease that affects people’s quality of life. Electroencephalography (EEG) signals are used to diagnose epileptic seizures. This paper provides a computer-aided diagnosis system (CADS) for the automatic diagnosis of epileptic seizures in EEG signals. The proposed method consists of three steps, including preprocessing, feature extraction, and classification. In order to perform the simulations, the Bonn and Freiburg datasets are used. Firstly, we used a band-pass filter with 0.5–40 Hz cut-off frequency for removal artifacts of the EEG datasets. Tunable-Q Wavelet Transform (TQWT) is used for EEG signal decomposition. In the second step, various linear and nonlinear features are extracted from TQWT sub-bands. In this step, various statistical, frequency, and nonlinear features are extracted from the sub-bands. The nonlinear features used are based on fractal dimensions (FDs) and entropy theories. In the classification step, different approaches based on conventional machine learning (ML) and deep learning (DL) are discussed. In this step, a CNN–RNN-based DL method with the number of layers proposed is applied. The extracted features have been fed to the input of the proposed CNN–RNN model, and satisfactory results have been reported. In the classification step, the K-fold cross-validation with k = 10 is employed to demonstrate the effectiveness of the proposed CNN–RNN classification procedure. The results revealed that the proposed CNN–RNN method for Bonn and Freiburg datasets achieved an accuracy of 99.71% and 99.13%, respectively.",
      "doi": "10.3390/s21227710",
      "source": "openalex",
      "citations": 77,
      "journal": "Sensors"
    },
    {
      "id": "openalex_996b46788f49",
      "title": "Organoid intelligence (OI): the new frontier in biocomputing and intelligence-in-a-dish",
      "authors": [
        "Lena Smirnova",
        "Brian Caffo",
        "David H. Gracias",
        "Qi Huang",
        "Itzy E. Morales Pantoja",
        "Bo‐Hao Tang",
        "Donald J. Zack",
        "Cynthia Berlinicke",
        "J. Lomax Boyd",
        "T.D. Harris"
      ],
      "year": 2023,
      "abstract": "Recent advances in human stem cell-derived brain organoids promise to replicate critical molecular and cellular aspects of learning and memory and possibly aspects of cognition in vitro . Coining the term “organoid intelligence” (OI) to encompass these developments, we present a collaborative program to implement the vision of a multidisciplinary field of OI. This aims to establish OI as a form of genuine biological computing that harnesses brain organoids using scientific and bioengineering advances in an ethically responsible manner. Standardized, 3D, myelinated brain organoids can now be produced with high cell density and enriched levels of glial cells and gene expression critical for learning. Integrated microfluidic perfusion systems can support scalable and durable culturing, and spatiotemporal chemical signaling. Novel 3D microelectrode arrays permit high-resolution spatiotemporal electrophysiological signaling and recording to explore the capacity of brain organoids to recapitulate the molecular mechanisms of learning and memory formation and, ultimately, their computational potential. Technologies that could enable novel biocomputing models via stimulus-response training and organoid-computer interfaces are in development. We envisage complex, networked interfaces whereby brain organoids are connected with real-world sensors and output devices, and ultimately with each other and with sensory organ organoids (e.g. retinal organoids), and are trained using biofeedback, big-data warehousing, and machine learning methods. In parallel, we emphasize an embedded ethics approach to analyze the ethical aspects raised by OI research in an iterative, collaborative manner involving all relevant stakeholders. The many possible applications of this research urge the strategic development of OI as a scientific discipline. We anticipate OI-based biocomputing systems to allow faster decision-making, continuous learning during tasks, and greater energy and data efficiency. Furthermore, the development of “intelligence-in-a-dish” could help elucidate the pathophysiology of devastating developmental and degenerative diseases (such as dementia), potentially aiding the identification of novel therapeutic approaches to address major global unmet needs.",
      "doi": "10.3389/fsci.2023.1017235",
      "source": "openalex",
      "citations": 213,
      "journal": "Frontiers in Science"
    },
    {
      "id": "openalex_1def826569bb",
      "title": "Artificial Intelligence and Neuroscience: Transformative Synergies in Brain Research and Clinical Applications",
      "authors": [
        "Răzvan Onciul",
        "Cătălina-Ioana Tătaru",
        "Adrian Dumitru",
        "Carla Crivoi",
        "Matei Șerban",
        "Răzvan-Adrian Covache-Busuioc",
        "Mugurel Petrinel Rădoi",
        "Corneliu Toader"
      ],
      "year": 2025,
      "abstract": "The convergence of Artificial Intelligence (AI) and neuroscience is redefining our understanding of the brain, unlocking new possibilities in research, diagnosis, and therapy. This review explores how AI’s cutting-edge algorithms—ranging from deep learning to neuromorphic computing—are revolutionizing neuroscience by enabling the analysis of complex neural datasets, from neuroimaging and electrophysiology to genomic profiling. These advancements are transforming the early detection of neurological disorders, enhancing brain–computer interfaces, and driving personalized medicine, paving the way for more precise and adaptive treatments. Beyond applications, neuroscience itself has inspired AI innovations, with neural architectures and brain-like processes shaping advances in learning algorithms and explainable models. This bidirectional exchange has fueled breakthroughs such as dynamic connectivity mapping, real-time neural decoding, and closed-loop brain–computer systems that adaptively respond to neural states. However, challenges persist, including issues of data integration, ethical considerations, and the “black-box” nature of many AI systems, underscoring the need for transparent, equitable, and interdisciplinary approaches. By synthesizing the latest breakthroughs and identifying future opportunities, this review charts a path forward for the integration of AI and neuroscience. From harnessing multimodal data to enabling cognitive augmentation, the fusion of these fields is not just transforming brain science, it is reimagining human potential. This partnership promises a future where the mysteries of the brain are unlocked, offering unprecedented advancements in healthcare, technology, and beyond.",
      "doi": "10.3390/jcm14020550",
      "source": "openalex",
      "citations": 58,
      "journal": "Journal of Clinical Medicine"
    },
    {
      "id": "openalex_f98f3fbf26fe",
      "title": "Effects of Age on Cortical Tracking of Word-Level Features of Continuous Competing Speech",
      "authors": [
        "Juraj Mesík",
        "Lucia Ray",
        "Magdalena Wojtczak"
      ],
      "year": 2021,
      "abstract": "Speech-in-noise comprehension difficulties are common among the elderly population, yet traditional objective measures of speech perception are largely insensitive to this deficit, particularly in the absence of clinical hearing loss. In recent years, a growing body of research in young normal-hearing adults has demonstrated that high-level features related to speech semantics and lexical predictability elicit strong centro-parietal negativity in the EEG signal around 400 ms following the word onset. Here we investigate effects of age on cortical tracking of these word-level features within a two-talker speech mixture, and their relationship with self-reported difficulties with speech-in-noise understanding. While undergoing EEG recordings, younger and older adult participants listened to a continuous narrative story in the presence of a distractor story. We then utilized forward encoding models to estimate cortical tracking of four speech features: (1) word onsets, (2) “semantic” dissimilarity of each word relative to the preceding context, (3) lexical surprisal for each word, and (4) overall word audibility. Our results revealed robust tracking of all features for attended speech, with surprisal and word audibility showing significantly stronger contributions to neural activity than dissimilarity. Additionally, older adults exhibited significantly stronger tracking of word-level features than younger adults, especially over frontal electrode sites, potentially reflecting increased listening effort. Finally, neuro-behavioral analyses revealed trends of a negative relationship between subjective speech-in-noise perception difficulties and the model goodness-of-fit for attended speech, as well as a positive relationship between task performance and the goodness-of-fit, indicating behavioral relevance of these measures. Together, our results demonstrate the utility of modeling cortical responses to multi-talker speech using complex, word-level features and the potential for their use to study changes in speech processing due to aging and hearing loss.",
      "doi": "10.3389/fnins.2021.635126",
      "source": "openalex",
      "citations": 64,
      "journal": "Frontiers in Neuroscience"
    },
    {
      "id": "openalex_9d81287decf1",
      "title": "Parkinson’s Disease EMG Data Augmentation and Simulation with DCGANs and Style Transfer",
      "authors": [
        "Rafael Anicet Zanini",
        "Esther Luna Colombini"
      ],
      "year": 2020,
      "abstract": "This paper proposes two new data augmentation approaches based on Deep Convolutional Generative Adversarial Networks (DCGANs) and Style Transfer for augmenting Parkinson’s Disease (PD) electromyography (EMG) signals. The experimental results indicate that the proposed models can adapt to different frequencies and amplitudes of tremor, simulating each patient’s tremor patterns and extending them to different sets of movement protocols. Therefore, one could use these models for extending the existing patient dataset and generating tremor simulations for validating treatment approaches on different movement scenarios.",
      "doi": "10.3390/s20092605",
      "source": "openalex",
      "citations": 71,
      "journal": "Sensors"
    },
    {
      "id": "openalex_e916944db653",
      "title": "Real-time decoding of question-and-answer speech dialogue using human cortical activity",
      "authors": [
        "David A. Moses",
        "Matthew K. Leonard",
        "Joseph G. Makin",
        "Edward F. Chang"
      ],
      "year": 2019,
      "abstract": "Abstract Natural communication often occurs in dialogue, differentially engaging auditory and sensorimotor brain regions during listening and speaking. However, previous attempts to decode speech directly from the human brain typically consider listening or speaking tasks in isolation. Here, human participants listened to questions and responded aloud with answers while we used high-density electrocorticography (ECoG) recordings to detect when they heard or said an utterance and to then decode the utterance’s identity. Because certain answers were only plausible responses to certain questions, we could dynamically update the prior probabilities of each answer using the decoded question likelihoods as context. We decode produced and perceived utterances with accuracy rates as high as 61% and 76%, respectively (chance is 7% and 20%). Contextual integration of decoded question likelihoods significantly improves answer decoding. These results demonstrate real-time decoding of speech in an interactive, conversational setting, which has important implications for patients who are unable to communicate.",
      "doi": "10.1038/s41467-019-10994-4",
      "source": "openalex",
      "citations": 223,
      "journal": "Nature Communications"
    },
    {
      "id": "openalex_f1866a146508",
      "title": "An End-to-End Deep Learning Framework for Real-Time Denoising of Heart Sounds for Cardiac Disease Detection in Unseen Noise",
      "authors": [
        "Shams Nafisa Ali",
        "Samiul Based Shuvo",
        "Muhammad Ishtiaque Sayeed Al-Manzo",
        "Anwarul Hasan",
        "Taufiq Hasan"
      ],
      "year": 2023,
      "abstract": "&lt;p dir=\"ltr\"&gt;The heart sound signals captured via a digital stethoscope are often distorted by environmental and physiological noise, altering their salient and critical properties. The problem is exacerbated in crowded low-resource hospital settings with high noise levels which degrades the diagnostic performance. In this study, we present a novel deep encoder-decoder-based denoising architecture (LU-Net) to suppress ambient and internal lung sound noises. Training is done using a large benchmark PCG dataset mixed with physiological noise, i.e., breathing sounds. Two different noisy datasets were prepared for experimental evaluation by mixing unseen lung sounds and hospital ambient noises with the clean heart sound recordings. We also used the inherently noisy portion of the PASCAL heart sound dataset for evaluation. The proposed framework showed effective suppression of background noises in both unseen real-world data and synthetically generated noisy heart sound recordings, improving the signal-to-noise ratio (SNR) level by 5.575 dB on an average using only 1.32 M parameters. The proposed model outperforms the current state-of-the-art U-Net model with an average SNR improvement of 5.613 dB and 5.537 dB in the presence of lung sound and unseen hospital noise, respectively. LU-Net also outperformed the state-of-the-art Fully Convolutional Network (FCN) by 1.750 dB and 1.748 dB for lung sound and unseen hospital noise conditions, respectively. In addition, the proposed denoising method model improves classification accuracy by 38.93% in the noisy portion of the PASCAL heart sound dataset. The results presented in the paper indicate that our proposed architecture demonstrated a robust denoising performance on different datasets with diverse levels and characteristics of noise. The proposed deep learning-based PCG denoising approach is a pioneering study that can significantly improve the accuracy of computer-aided auscultation systems for detecting cardiac diseases in noisy, low-resource hospitals and underserved communities. &lt;/p&gt;&lt;h2&gt;Other Information&lt;/h2&gt;&lt;p dir=\"ltr\"&gt;Published in: IEEE Access&lt;br&gt;License: &lt;a href=\"http://creativecommons.org/licenses/by/4.0\" target=\"_blank\"&gt;http://creativecommons.org/licenses/by/4.0&lt;/a&gt;&lt;br&gt;See article on publisher's website: &lt;a href=\"https://dx.doi.org/10.1109/access.2023.3292551\" target=\"_blank\"&gt;https://dx.doi.org/10.1109/access.2023.3292551&lt;/a&gt;&lt;/p&gt;",
      "doi": "10.1109/access.2023.3292551",
      "source": "openalex",
      "citations": 41,
      "journal": "IEEE Access"
    },
    {
      "id": "openalex_03d4c9076d7d",
      "title": "Soft Electronics for Health Monitoring Assisted by Machine Learning",
      "authors": [
        "Yancong Qiao",
        "Jinan Luo",
        "Tianrui Cui",
        "Haidong Liu",
        "Hao Tang",
        "Ying-Fen Zeng",
        "Chang Liu",
        "Yuanfang Li",
        "Jinming Jian",
        "Jingzhi Wu"
      ],
      "year": 2023,
      "abstract": "Abstract Due to the development of the novel materials, the past two decades have witnessed the rapid advances of soft electronics. The soft electronics have huge potential in the physical sign monitoring and health care. One of the important advantages of soft electronics is forming good interface with skin, which can increase the user scale and improve the signal quality. Therefore, it is easy to build the specific dataset, which is important to improve the performance of machine learning algorithm. At the same time, with the assistance of machine learning algorithm, the soft electronics have become more and more intelligent to realize real-time analysis and diagnosis. The soft electronics and machining learning algorithms complement each other very well. It is indubitable that the soft electronics will bring us to a healthier and more intelligent world in the near future. Therefore, in this review, we will give a careful introduction about the new soft material, physiological signal detected by soft devices, and the soft devices assisted by machine learning algorithm. Some soft materials will be discussed such as two-dimensional material, carbon nanotube, nanowire, nanomesh, and hydrogel. Then, soft sensors will be discussed according to the physiological signal types (pulse, respiration, human motion, intraocular pressure, phonation, etc.). After that, the soft electronics assisted by various algorithms will be reviewed, including some classical algorithms and powerful neural network algorithms. Especially, the soft device assisted by neural network will be introduced carefully. Finally, the outlook, challenge, and conclusion of soft system powered by machine learning algorithm will be discussed.",
      "doi": "10.1007/s40820-023-01029-1",
      "source": "openalex",
      "citations": 87,
      "journal": "Nano-Micro Letters"
    },
    {
      "id": "openalex_f25743a08e85",
      "title": "Cross-Subject Zero Calibration Driver’s Drowsiness Detection: Exploring Spatiotemporal Image Encoding of EEG Signals for Convolutional Neural Network Classification",
      "authors": [
        "João Paulo",
        "Gabriel Pires",
        "Urbano Nunes"
      ],
      "year": 2021,
      "abstract": "This paper explores two methodologies for drowsiness detection using EEG signals in a sustained-attention driving task considering pre-event time windows, and focusing on cross-subject zero calibration. Driving accidents are a major cause of injuries and deaths on the road. A considerable portion of those are due to fatigue and drowsiness. Advanced driver assistance systems that could detect mental states which are associated with hazardous situations, such as drowsiness, are of critical importance. EEG signals are used widely for brain-computer interfaces, as well as mental state recognition. However, these systems are still difficult to design due to very low signal-to-noise ratios and cross-subject disparities, requiring individual calibration cycles. To tackle this research domain, here, we explore drowsiness detection based on EEG signals' spatiotemporal image encoding representations in the form of either recurrence plots or gramian angular fields for deep convolutional neural network (CNN) classification. Results comparing both techniques using a public dataset of 27 subjects show a superior balanced accuracy of up to 75.87% for leave-one-out cross-validation, using both techniques, against works in the literature, demonstrating the possibility to pursue cross-subject zero calibration design.",
      "doi": "10.1109/tnsre.2021.3079505",
      "source": "openalex",
      "citations": 73,
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "id": "openalex_92085c3f6d46",
      "title": "Birdsong Denoising Using Wavelets",
      "authors": [
        "Nirosha Priyadarshani",
        "Stephen Marsland",
        "Isabel Castro",
        "Amal Punchihewa"
      ],
      "year": 2016,
      "abstract": "Automatic recording of birdsong is becoming the preferred way to monitor and quantify bird populations worldwide. Programmable recorders allow recordings to be obtained at all times of day and year for extended periods of time. Consequently, there is a critical need for robust automated birdsong recognition. One prominent obstacle to achieving this is low signal to noise ratio in unattended recordings. Field recordings are often very noisy: birdsong is only one component in a recording, which also includes noise from the environment (such as wind and rain), other animals (including insects), and human-related activities, as well as noise from the recorder itself. We describe a method of denoising using a combination of the wavelet packet decomposition and band-pass or low-pass filtering, and present experiments that demonstrate an order of magnitude improvement in noise reduction over natural noisy bird recordings.",
      "doi": "10.1371/journal.pone.0146790",
      "source": "openalex",
      "citations": 68,
      "journal": "PLoS ONE"
    },
    {
      "id": "openalex_31ad99c19d3e",
      "title": "Approaches to Multi-Objective Feature Selection: A Systematic Literature Review",
      "authors": [
        "Qasem Al-Tashi",
        "Said Jadid Abdulkadir",
        "Helmi Md Rais",
        "Seyedali Mirjalili",
        "Hitham Alhussian"
      ],
      "year": 2020,
      "abstract": "Feature selection has gained much consideration from scholars working in the domain of machine learning and data mining in recent years. Feature selection is a popular problem in Machine learning with the goal of finding optimal features with increase accuracy. As a result, several studies have been conducted on multi-objective feature selection through numerous multi-objective techniques and algorithms. The objective of this paper is to present a systematic literature review of the challenges and issues of the multi-objective feature selection problem and critically analyses the proposed techniques used to tackle this problem. The conducted review covered all related studies published since 2012 up to 2019. The outcomes of the reviewed of these studies clearly showed that no perfect solution to the multi-objective feature selection problem yet. The authors believed that the conducted review would serve as the main source of the techniques and methods used to resolve the problem of multi-objective feature selection. Furthermore, current challenges and issues are deliberated to find promising research domains for further study.",
      "doi": "10.1109/access.2020.3007291",
      "source": "openalex",
      "citations": 168,
      "journal": "IEEE Access"
    },
    {
      "id": "pubmed_1243ae268f7c",
      "title": "EEG Artifact Removal using Stacked Multi-Head Attention Transformer Architecture.",
      "authors": [
        "Gowtham Reddy N",
        "Debashree Guha",
        "Manjunatha Mahadevappa"
      ],
      "year": 2024,
      "abstract": "This study presents a transformer attention model with stacked multi-head attention layer designed to remove noise from electroencephalogram (EEG) signals, specifically addressing the problem of signal distortion caused by artifacts such as ocular and muscular noise. This is a crucial step in improving the efficacy of EEG, for disease diagnostics and BCI applications. Deep learning (DL) models have been increasingly employed for denoising EEG data in recent years, demonstrating comparable performance to classical approaches. However, the current models have been unsuccessful in capturing temporal long-term dependencies to efficiently eliminating ocular and muscular abnormalities. In this study, we address those challenges faced in the DL models by introducing multiple multi-head attention layers in the transformer model, which surpass the performance measures of previous works in EEGdenoiseNet dataset.",
      "doi": "10.1109/EMBC53108.2024.10782044",
      "source": "pubmed",
      "citations": null,
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference"
    },
    {
      "id": "pubmed_40d5cd209798",
      "title": "A GAN Guided Parallel CNN and Transformer Network for EEG Denoising.",
      "authors": [
        "Jin Yin",
        "Aiping Liu",
        "Chang Li",
        "Ruobing Qian",
        "Xun Chen"
      ],
      "year": 2025,
      "abstract": "Electroencephalography (EEG) signals are often contaminated with various physiological artifacts, seriously affecting the quality of subsequent analysis. Therefore, removing artifacts is an essential step in practice. As of now, deep learning-based EEG denoising methods have exhibited unique advantages over traditional methods. However, they still suffer from the following limitations. The existing structure designs have not fully taken into account the temporal characteristics of artifacts. Meanwhile, the existing training strategies usually ignore the holistic consistency between denoised EEG signals and authentic clean ones. To address these issues, we propose a GAN guided parallel CNN and transformer network, named GCTNet. The generator contains parallel CNN blocks and transformer blocks to respectively capture local and global temporal dependencies. Then, a discriminator is employed to detect and correct the holistic inconsistencies between clean and denoised EEG signals. We evaluate the proposed network on both semi-simulated and real data. Extensive experimental results demonstrate that GCTNet significantly outperforms state-of-the-art networks in various artifact removal tasks, as evidenced by its superior objective evaluation metrics. For example, in the task of removing electromyography artifacts, GCTNet achieves 11.15% reduction in RRMSE and 9.81% improvement in SNR over other methods, highlighting the potential of the proposed method as a promising solution for EEG signals in practical applications.",
      "doi": "10.1109/JBHI.2023.3277596",
      "source": "pubmed",
      "citations": null,
      "journal": "IEEE journal of biomedical and health informatics"
    },
    {
      "id": "pubmed_cc4112b8d63b",
      "title": "EEGDnet: Fusing non-local and local self-similarity for EEG signal denoising with transformer.",
      "authors": [
        "Xiaorong Pu",
        "Peng Yi",
        "Kecheng Chen",
        "Zhaoqi Ma",
        "Di Zhao",
        "Yazhou Ren"
      ],
      "year": 2022,
      "abstract": "Electroencephalogram (EEG) has shown a useful approach to produce a brain-computer interface (BCI). One-dimensional (1-D) EEG signal is yet easily disturbed by certain artifacts (a.k.a. noise) due to the high temporal resolution. Thus, it is crucial to remove the noise in received EEG signal. Recently, deep learning-based EEG signal denoising approaches have achieved impressive performance compared with traditional ones. It is well known that the characteristics of self-similarity (including non-local and local ones) of data (e.g., natural images and time-domain signals) are widely leveraged for denoising. However, existing deep learning-based EEG signal denoising methods ignore either the non-local self-similarity (e.g., 1-D convolutional neural network) or local one (e.g., fully connected network and recurrent neural network). To address this issue, we propose a novel 1-D EEG signal denoising network with 2-D transformer, namely EEGDnet. Specifically, we comprehensively take into account the non-local and local self-similarity of EEG signal through the transformer module. By fusing non-local self-similarity in self-attention blocks and local self-similarity in feed forward blocks, the negative impact caused by noises and outliers can be reduced significantly. Extensive experiments show that, compared with other state-of-the-art models, EEGDnet achieves much better performance in terms of both quantitative and qualitative metrics. Specifically, EEGDnet can achieve 18% and 11% improvements in correlation coefficients when removing ocular artifacts and muscle artifacts, respectively.",
      "doi": "10.1016/j.compbiomed.2022.106248",
      "source": "pubmed",
      "citations": null,
      "journal": "Computers in biology and medicine"
    },
    {
      "id": "pubmed_efc6d3b6eacc",
      "title": "EEGDfus: A Conditional Diffusion Model for Fine-Grained EEG Denoising.",
      "authors": [
        "Xiaoyang Huang",
        "Chang Li",
        "Aiping Liu",
        "Ruobing Qian",
        "Xun Chen"
      ],
      "year": 2025,
      "abstract": "Electroencephalogram (EEG) signals are vital in understanding brain activity, but their weak amplitude makes them susceptible to various artifacts. Accurate denoising of EEG data is crucial as a preprocessing step to ensure precise analysis and interpretation. In recent years, the diffusion model has garnered significant attention as a promising approach in generative modeling. This model effectively addresses the issue of over-smoothing in existing deep learning methods and thus has the potential to generate more refined denoised EEG signals. However, the generation process of the standard diffusion model is highly random, limiting its direct application to EEG denoising tasks. To address this limitation, we propose a conditional diffusion model specifically designed for EEG denoising. In this model, the standard diffusion model's denoising network is replaced by a novel dual-branch network, where noisy EEG information is used as a condition to guide the generation of corresponding clean EEG signals. This dual-branch structure leverages the complementary strengths of convolutional neural network (CNN) and Transformer architectures, integrating multi-scale features to comprehensively extract information from the signal. Extensive experiments demonstrate the remarkable performance of EEGDfus in EEG denoising. We tested it on two public datasets. Testing on two public datasets, EEGdenoiseNet and SSED, demonstrated that after denoising, the average correlation coefficient increased to 0.983 and 0.992 for EOG artifact removal, respectively. The proposed model outperforms commonly used baseline models, setting a new state-of-the-art benchmark in the field of EEG denoising.",
      "doi": "10.1109/JBHI.2024.3504716",
      "source": "pubmed",
      "citations": null,
      "journal": "IEEE journal of biomedical and health informatics"
    },
    {
      "id": "pubmed_e52a37d84d5c",
      "title": "DHCT-GAN: Improving EEG Signal Quality with a Dual-Branch Hybrid CNN-Transformer Network.",
      "authors": [
        "Yinan Cai",
        "Zhao Meng",
        "Dian Huang"
      ],
      "year": 2025,
      "abstract": "Electroencephalogram (EEG) signals are important bioelectrical signals widely used in brain activity studies, cognitive mechanism research, and the diagnosis and treatment of neurological disorders. However, EEG signals are often influenced by various physiological artifacts, which can significantly affect data analysis and diagnosis. Recently, deep learning-based EEG denoising methods have exhibited unique advantages over traditional methods. Most existing methods mainly focus on identifying the characteristics of clean EEG signals to facilitate artifact removal; however, the potential to integrate cross-disciplinary knowledge, such as insights from artifact research, remains an area that requires further exploration. In this study, we developed DHCT-GAN, a new EEG denoising model, using a dual-branch hybrid network architecture. This model independently learns features from both clean EEG signals and artifact signals, then fuses this information through an adaptive gating network to generate denoised EEG signals that accurately preserve EEG signal features while effectively removing artifacts. We evaluated DHCT-GAN's performance through waveform analysis, power spectral density (PSD) analysis, and six performance metrics. The results demonstrate that DHCT-GAN significantly outperforms recent state-of-the-art networks in removing various artifacts. Furthermore, ablation experiments revealed that the hybrid model surpasses single-branch models in artifact removal, underscoring the crucial role of artifact knowledge constraints in improving denoising effectiveness.",
      "doi": "10.3390/s25010231",
      "source": "pubmed",
      "citations": null,
      "journal": "Sensors (Basel, Switzerland)"
    },
    {
      "id": "pubmed_d2931d4b1a81",
      "title": "Federated deep learning model for epilepsy seizure detection using electroencephalogram (EEG) signal.",
      "authors": [
        "G R Abijith",
        "S Jothi",
        "Chandrasekar A"
      ],
      "year": 2025,
      "abstract": "Epilepsy is a chronic neurological disorder characterized by recurrent seizures due to abnormal brain activity, which affects individuals' health and quality of life. Traditional seizure detection methods face challenges related to data privacy and security as well as difficulty in fully capturing both temporal and spatial relationships within the Electroencephalography signal. To address these limitations, a Federated Learning Enabled Unified Transformer model is proposed.",
      "doi": "10.1080/01616412.2025.2555516",
      "source": "pubmed",
      "citations": null,
      "journal": "Neurological research"
    },
    {
      "id": "pubmed_6949c0cfea13",
      "title": "Adaptive Prototype-Based Subtle Transient Pattern Transformers for Enhanced Neonatal Seizure Classification and Severity Assessment.",
      "authors": [
        "P T Priyanga",
        "R P Anto Kumar"
      ],
      "year": 2025,
      "abstract": "Neonatal seizures are important neurological episodes that need to be identified and managed early to prevent adverse effects. Cohort comparison and rule-based models do not account for the nuances of electroencephalography (EEG) signals and require much time to analyse and interpret raw neonatal EEG signals. The latest advancements in AI-based methods demonstrate the possibility of such tasks, but they still possess some drawbacks, such as a requirement for big labelled datasets, inefficiency in computation processes and noise sensitivity, which hinder clinical use. In this regard, to overcome these limitations, the new multi-component framework named Adaptive Prototype-Based Subtle Transient Pattern Aware Transformer (APSTPT) is introduced for neonate seizure detection, classification and its severity quantification. Pre-processing is the first stage, where noise and artefacts are removed, and only relevant brain signals are amplified. This is succeeded by feature extraction, where power spectral density and phase locking value components are used to identify important spectral and phase-synchronisation characteristics. These aspects are fine-tuned using cross-channel covariance attention to handle inter-channel dependencies. Real-time adaptation of the prototype with the use of prototype learning makes the classification of seizure types better and more dynamic because the finer details of the signal are captured. Moreover, multiscale entropy analysis measures the signal complexity across different temporal scales and properly differentiates the severity of the seizure into mild, moderate and severe cases, respectively. This structured approach allows for accurate separation of seizure events on the time-series and also flexibility according to the characteristics of different datasets. Experiments conducted using the TUH EEG Corpus and Zenodo dataset prove the effectiveness of the proposed framework, with a classification accuracy of 99.74% and a severity assessment accuracy of 98.87%, which is higher than previous approaches. Therefore, the APSTPT framework presents stable performance irrespective of window lengths and the condition of different datasets, showing its flexibility for real-time implementation in the clinical setting.",
      "doi": "10.1002/jdn.70059",
      "source": "pubmed",
      "citations": null,
      "journal": "International journal of developmental neuroscience : the official journal of the International Society for Developmental Neuroscience"
    },
    {
      "id": "pubmed_c98a92ebd8b7",
      "title": "GLEAM: A multimodal deep learning framework for chronic lower back pain detection using EEG and sEMG signals.",
      "authors": [
        "Sagnik De",
        "Prithwijit Mukherjee",
        "Anisha Halder Roy"
      ],
      "year": 2025,
      "abstract": "Low Back Pain (LBP) is the most prevalent musculoskeletal condition worldwide and a leading cause of disability, significantly affecting mobility, work productivity, and overall quality of life. Due to its high prevalence and substantial economic burden, LBP presents a critical global public health challenge that demands innovative diagnostic and therapeutic solutions. This study introduces a novel deep-learning approach for diagnosing LBP intensity using electroencephalography (EEG) signals and surface electromyography (sEMG) signals from back muscles. A GAN-Convolution-Transformer-based model, named GLEAM (GAN-ConvoLution-sElf Attention-ETLSTM), is designed to classify LBP intensity into four categories: no LBP, mild LBP, moderate LBP, and intolerable LBP. A denoising GAN is central to the model's functionality, playing a pivotal role in enhancing the quality of EEG and sEMG signals by removing noise, resulting in cleaner and more accurate input data. Various features are extracted from the GAN-denoised EEG and sEMG signals, and the combined features from both EEG and sEMG are used for LBP detection. After the feature extraction, the CNN is employed to capture local temporal patterns within the data, allowing the model to focus on smaller, region-specific trends in the signals. Subsequently, the self-attention module identifies global correlations among these locally extracted features, enhancing the model's ability to recognize broader patterns. The proposed ETLSTM network performs the final classification, which achieves an impressive LBP detection accuracy of 98.95%. This research presents several innovative contributions: (i) the development of a novel denoising GAN for cleaning EEG and sEMG signals, (ii) the design and integration of a new ETLSTM architecture as a classifier within the GLEAM model, and (iii) the introduction of the GLEAM hybrid deep learning framework, which enables robust and reliable LBP intensity assessment.",
      "doi": "10.1016/j.compbiomed.2025.109928",
      "source": "pubmed",
      "citations": null,
      "journal": "Computers in biology and medicine"
    }
  ]
}